{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UPL_Assignment_203190027.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rituraj123450/AI-Project-Web-Application-for-object-identification-/blob/main/UPL_Assignment_203190027.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from FeatureExtractor import FeatureExtractor\n",
        "from BOW import BOW\n",
        "from pybrain.datasets.supervised import SupervisedDataSet\n",
        "from pybrain.tools.shortcuts import buildNetwork\n",
        "from pybrain.supervised.trainers import BackpropTrainer\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "_3XMO03dEI36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xbZQBnhN4FZ",
        "outputId": "5812a896-082c-4fce-f113-9ef51fdd2856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadImage:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def loadTrainImage(self,path):\n",
        "        '''\n",
        "        load all train images from the path\n",
        "        :param path: the images' path\n",
        "        :return: the type and the name of all insects, the path of all insect images\n",
        "        '''\n",
        "\n",
        "        # get all species' names\n",
        "        insectSpecies = os.listdir(path)\n",
        "\n",
        "        trainingPaths = []\n",
        "        names = []\n",
        "        # get full list of all training images\n",
        "        for p in insectSpecies:\n",
        "            paths = os.listdir(path + \"\\\\\" + p)\n",
        "            for j in paths:\n",
        "                trainingPaths.append(path + \"\\\\\" + p + \"\\\\\" + j)\n",
        "                names.append(p)\n",
        "\n",
        "        return insectSpecies,names,trainingPaths"
      ],
      "metadata": {
        "id": "YpjbK_mkEDCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def getSiftFeature(self, image):\n",
        "        '''\n",
        "        get the sift features from a insect image\n",
        "        :param image:\n",
        "        :return:the descriptor of the image\n",
        "        '''\n",
        "        sift = cv2.SIFT()\n",
        "        imgBlur = cv2.GaussianBlur(image, (5, 5), 0)  # Remove noise\n",
        "        gray = cv2.cvtColor(imgBlur, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
        "        kp, dsc = sift.detectAndCompute(gray, None)  # get keypoint and descriptor\n",
        "        return dsc\n",
        "\n",
        "    def getSurfFeature(self, image):\n",
        "        '''\n",
        "        get the surf features from a insect image\n",
        "        :param image:\n",
        "        :return: the descriptor of the image\n",
        "        '''\n",
        "        surf = cv2.SURF()\n",
        "        imgBlur = cv2.GaussianBlur(image, (5, 5), 0)  # Remove noise\n",
        "        gray = cv2.cvtColor(imgBlur, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
        "        kp, dsc = surf.detectAndCompute(gray, None)  # get keypoint and descriptor\n",
        "        return dsc\n",
        "\n",
        "\n",
        "    def getSingleFeature(self, path, bowDictionary, featureExtraType):\n",
        "        '''\n",
        "        get an image's feature by using Bag of words dictionary\n",
        "        :param path:image's path\n",
        "        :param bowDictionary:the dictionary of Bag of words\n",
        "        :param featureExtraType:the feature type:sift or surf\n",
        "        :return:\n",
        "        '''\n",
        "        im = cv2.imread(path, 1)\n",
        "        gray = cv2.cvtColor(im, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
        "        if (featureExtraType.upper() == \"SIFT\"):\n",
        "            return bowDictionary.compute(gray, cv2.SIFT().detect(gray))\n",
        "        if (featureExtraType.upper() == \"SURF\"):\n",
        "            return bowDictionary.compute(gray, cv2.SURF().detect(gray))"
      ],
      "metadata": {
        "id": "0QeLBHwVEikh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BOW:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def getBowDictionary(self,dictionarySize, descriptors, featureExtraType):\n",
        "        '''\n",
        "        get the dictionary of Bog of words\n",
        "        :param dictionarySize: the size of dictionary\n",
        "        :param descriptors: the all images' descriptors\n",
        "        :param featureExtraType: the feature type: sift or surf\n",
        "        :return: the dictionary of Bag of words\n",
        "        '''\n",
        "        BOW = cv2.BOWKMeansTrainer(dictionarySize)\n",
        "        for dsc in descriptors:\n",
        "            BOW.add(dsc)\n",
        "\n",
        "        # dictionary created\n",
        "        dictionary = BOW.cluster()\n",
        "\n",
        "        if (featureExtraType.upper() == \"SIFT\"):\n",
        "            extra = cv2.DescriptorExtractor_create(\"SIFT\")\n",
        "        if (featureExtraType.upper() == \"SURF\"):\n",
        "            extra = cv2.DescriptorExtractor_create(\"SURF\")\n",
        "        bowDictionary = cv2.BOWImgDescriptorExtractor(extra, cv2.BFMatcher(cv2.NORM_L2))\n",
        "        bowDictionary.setVocabulary(dictionary)\n",
        "        return bowDictionary\n",
        "\n",
        "    def getDescriptors(self, path, featureExtraType):\n",
        "        '''\n",
        "        get all descriptors from images in the path\n",
        "        :param path: the image's path\n",
        "        :param featureExtraType: the feature type:sift or surf\n",
        "        :return: all images' descriptors\n",
        "        '''\n",
        "        featureExtra = FeatureExtractor()\n",
        "        descriptors = []\n",
        "        for p in path:\n",
        "            image = cv2.imread(p)\n",
        "            if (featureExtraType.upper() == \"SIFT\"):\n",
        "                dsc = featureExtra.getSiftFeature(image)\n",
        "            if (featureExtraType.upper() == \"SURF\"):\n",
        "                dsc = featureExtra.getSurfFeature(image)\n",
        "            descriptors.append(dsc)\n",
        "\n",
        "        return descriptors"
      ],
      "metadata": {
        "id": "f-rp19o3Euqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_ym-CWQAxHU"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Classify:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def algoSVM(self,trainingPath, testPath, featureExtraType):\n",
        "        '''\n",
        "        Using Support Vector Machine algorithm to classify insect images\n",
        "        :param trainingPath: the path of training images\n",
        "        :param testPath: he path of testing images\n",
        "        :param featureExtraType: the feature type : sift or surf\n",
        "        :return:\n",
        "        '''\n",
        "        loadImage = LoadImage()\n",
        "        featureExtra = FeatureExtractor()\n",
        "        bow = BOW()\n",
        "\n",
        "        #get the species,the name of all insects, the path of all insect images\n",
        "        insectSpecies, names, trainingPaths = loadImage.loadTrainImage(trainingPath)\n",
        "        print(insectSpecies)\n",
        "        print(\"Length of Data :\", len(insectSpecies))\n",
        "        dictionarySize = len(insectSpecies)\n",
        "\n",
        "        insect = {}\n",
        "        num = 1\n",
        "        for name in insectSpecies:\n",
        "            insect[name] = num\n",
        "            num += 1\n",
        "\n",
        "        #get the descriptors of all training images\n",
        "        descriptors = bow.getDescriptors(trainingPaths, featureExtraType)\n",
        "        #get Bag of Words dictionary\n",
        "        bowDictionary = bow.getBowDictionary(dictionarySize, descriptors, featureExtraType)\n",
        "        print(\"bow dictionary\")\n",
        "\n",
        "        #train data\n",
        "        trainDesc = []\n",
        "        #train response\n",
        "        trainLabels = []\n",
        "        i = 0\n",
        "\n",
        "        #initialize train datas and train responses\n",
        "        for p in trainingPaths:\n",
        "            trainDesc.extend(featureExtra.getSingleFeature(p, bowDictionary, featureExtraType))\n",
        "            trainLabels.append(insect[names[i]])\n",
        "            i = i + 1\n",
        "\n",
        "        svm = cv2.SVM()\n",
        "        #training\n",
        "        svm.train(np.array(trainDesc), np.array(trainLabels))\n",
        "\n",
        "        testInsectNames = os.listdir(testPath)\n",
        "        # Initialize a zero matrix to save the classification results\n",
        "        result = np.zeros((dictionarySize, dictionarySize))\n",
        "        print(\"result zero\")\n",
        "\n",
        "        count = 0\n",
        "        #classify all the test immages\n",
        "        for test in testInsectNames:\n",
        "            testingImage = os.listdir(testPath + \"\\\\\" + test)\n",
        "            for p in testingImage:\n",
        "                #get feature from a test image\n",
        "                feature = featureExtra.getSingleFeature(testPath + \"\\\\\" + test + \"\\\\\" + p, bowDictionary, featureExtraType)\n",
        "                #predict\n",
        "                p = svm.predict(feature)\n",
        "                #save the result in the result matrix\n",
        "                result[count, p - 1] += 1\n",
        "\n",
        "            count += 1\n",
        "\n",
        "        return result\n",
        "\n",
        "    def algoANN(self, trainingPath, testPath, featureExtraType, epochs):\n",
        "        '''\n",
        "        Using Artificial Neural Network algorithm to classify insect images\n",
        "        :param trainingPath: the path of training images\n",
        "        :param testPath:  the path of testing images\n",
        "        :param featureExtraType:  the feature type:sift or surf\n",
        "        :param epochs: the numbre of training for neural network\n",
        "        :return: the classification results\n",
        "        '''\n",
        "        loadImage = LoadImage()\n",
        "        featureExtra = FeatureExtractor()\n",
        "        bow = BOW()\n",
        "\n",
        "        # get the species,the name of all insects, the path of all insect images\n",
        "        insectNames, names, trainingPaths = loadImage.loadTrainImage(trainingPath)\n",
        "        insectSpecies = len(insectNames)\n",
        "        print(\"insect species:\", insectSpecies)\n",
        "\n",
        "        #get all descriptos of training images\n",
        "        trainDescriptors = bow.getDescriptors(trainingPaths, featureExtraType)\n",
        "        #get the BoW dictionary of trianing images\n",
        "        trainBowDictionary = bow.getBowDictionary(insectSpecies, trainDescriptors, featureExtraType)\n",
        "\n",
        "        #initialize a Neural Network\n",
        "        net = buildNetwork(insectSpecies, 100, 100, insectSpecies)\n",
        "        #initialize a data set\n",
        "        ds = SupervisedDataSet(insectSpecies, insectSpecies)\n",
        "        species = 0\n",
        "        #add all datas in data set\n",
        "        for p in insectNames:\n",
        "            trainingPaths = os.listdir(trainingPath + \"\\\\\" + p)\n",
        "            for j in trainingPaths:\n",
        "                #add data\n",
        "                ds.addSample(featureExtra.getSingleFeature(trainingPath + \"\\\\\" + p + \"\\\\\" + j,\n",
        "                                                           trainBowDictionary, featureExtraType)[0], (species,))\n",
        "            species += 1\n",
        "\n",
        "        #initialize a trainer\n",
        "        trainer = BackpropTrainer(net, ds, learningrate=0.01, momentum=0.1, weightdecay=0.01)\n",
        "        #training\n",
        "        for i in range(1, epochs):\n",
        "            traError = trainer.train()\n",
        "            print('after %d epochs,train error:%f' % (i, traError))\n",
        "\n",
        "        testInsectNames, testNames, testingPaths = loadImage.loadTrainImage(testPath)\n",
        "        testDescriptors = bow.getDescriptors(testingPaths, featureExtraType)\n",
        "        testBowDictionary = bow.getBowDictionary(insectSpecies, testDescriptors, featureExtraType)\n",
        "        # Initializes a zero matrix to save the classification results\n",
        "        result = np.zeros((insectSpecies, insectSpecies))\n",
        "\n",
        "        count = 0\n",
        "        # classify all the test immages\n",
        "        for m in testInsectNames:\n",
        "            testPaths = os.listdir(testPath + \"\\\\\" + m)\n",
        "            for n in testPaths:\n",
        "                test = net.activate(featureExtra.getSingleFeature(testPath + \"\\\\\" + m + \"\\\\\" + n,\n",
        "                                                                  testBowDictionary, featureExtraType)[0])\n",
        "                target = map(lambda x: (x), test)  # numpy.array to list\n",
        "                result[count, target.index(max(target))] += 1\n",
        "            count += 1\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MzaWmR61Igwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start = time.clock()\n",
        "    classify = Classify()\n",
        "    #please change the file path accordingly\n",
        "    trainingPath = \"C:\\\\Users\\\\ace\\\\Desktop\\\\newData\\\\training\"\n",
        "    testPath = \"C:\\\\Users\\\\ace\\\\Desktop\\\\newData\\\\testing\"\n",
        "\n",
        "    featureExtraType = \"surf\"\n",
        "    result = classify.algoSVM(trainingPath, testPath, featureExtraType)\n",
        "\n",
        "    end  = time.clock()\n",
        "    print(\"run time: %f s\" % (end - start))\n",
        "\n",
        "    print(result)\n",
        "    print(\"Error:%f\" % (result.trace() / result.sum()))"
      ],
      "metadata": {
        "id": "CIzwmUdgFHcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}